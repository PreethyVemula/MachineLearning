{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import logging\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble._forest import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "class IllnessPredictionModelWorkflow():\n",
    "    \"\"\"\n",
    "    Class instance to orchestrate model workflow\n",
    "    \"\"\"\n",
    "    def __init__(self, train_data_path=None, test_data_path=None):\n",
    "        \"\"\"\n",
    "        This method used to initialize the class instance attributes\n",
    "        :param train_data_path: train data CSV path\n",
    "        :param test_data_path: test data CSV path\n",
    "        \"\"\"\n",
    "        self.workflow_steps = [\"Load the train and test\",\n",
    "                               \"Preprocess the train and test\",\n",
    "                               \"Build a predictive model with the train\",\n",
    "                               \"Predict the outcome on the validation and test\",\n",
    "                               \"Exit\"]\n",
    "        self.workflow_dict = {self.workflow_steps[0]: \"Not Started\",\n",
    "                              self.workflow_steps[1]: \"Not Started\",\n",
    "                              self.workflow_steps[2]: \"Not Started\",\n",
    "                              self.workflow_steps[3]: \"Not Started\",\n",
    "                              self.workflow_steps[4]: \"Not Started\"}\n",
    "        self.model_names = ['Decision Tree',\n",
    "                            'Random Forest',\n",
    "                            'Grandient Boosting Regression']\n",
    "        self.model_dict = {self.model_names[0]: DecisionTreeClassifier(),\n",
    "                           self.model_names[1]: RandomForestClassifier(),\n",
    "                           self.model_names[2]: GradientBoostingRegressor()}\n",
    "\n",
    "        self.train_data_path = train_data_path\n",
    "        self.test_data_path = test_data_path\n",
    "        self.train_dataset = None\n",
    "        self.test_dataset = None\n",
    "        self.selected_features = None\n",
    "        self.prediction_column = [\"Illness\"]\n",
    "        self.selected_model = None\n",
    "        self.test_data_output_csv = \"./test_data_y_pred.csv\"\n",
    "\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        This method used to load train and test data\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.train_dataset = pd.read_csv(self.train_data_path)\n",
    "            self.test_dataset = pd.read_csv(self.test_data_path)\n",
    "        except FileNotFoundError as ex:\n",
    "            logging.error(ex)\n",
    "            raise ex\n",
    "\n",
    "        print('The data set is loaded')\n",
    "\n",
    "    def preprocess_data(self, input_df):\n",
    "        \"\"\"\n",
    "        This method used to pre-process the data\n",
    "        :param input_df: input data frame to pre-process the data\n",
    "        :return: processed data set\n",
    "        \"\"\"\n",
    "        dict_illness = {'No': 0, 'Yes': 1}\n",
    "        dict_sex = {'Male': 0, 'Female': 1}\n",
    "        simple_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "        # Id_Number,City,Gender,Age,Weight,Illness\n",
    "        data_columns = list(input_df.columns)\n",
    "        processed_dataset = input_df[data_columns].dropna()\n",
    "\n",
    "        simple_imputer.fit(processed_dataset[['Age']])\n",
    "        processed_dataset[['Age']] = simple_imputer.transform(processed_dataset[['Age']])\n",
    "\n",
    "        if \"Illness\" in data_columns:\n",
    "            processed_dataset['Illness'] = processed_dataset[self.prediction_column].replace(dict_illness)\n",
    "\n",
    "        processed_dataset['Gender'] = processed_dataset['Gender'].replace(dict_sex)\n",
    "        label_encoder = LabelEncoder()\n",
    "        processed_dataset['City'] = label_encoder.fit(processed_dataset[\"City\"])\\\n",
    "                                    .transform(processed_dataset[\"City\"])\n",
    "\n",
    "        return processed_dataset\n",
    "\n",
    "\n",
    "    def build_model(self, x_train_data=None, y_train_data=None):\n",
    "        \"\"\"\n",
    "        BUILD REGRESSION MODEL WITH 0.68 and it will be > 91%\n",
    "        This method will receive X , Y training data set and build a model based on user choice\n",
    "        :param x_train_data: X axis training data set\n",
    "        :param y_train_data: Y axis training data set\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        for i, name in enumerate(self.model_names):\n",
    "            print(f' {i+1}) {name}')\n",
    "\n",
    "        print('Please choose the model: ')\n",
    "\n",
    "        model_index = int(input()) - 1\n",
    "\n",
    "        clf = self.model_dict[self.model_names[model_index]].fit(x_train_data, y_train_data)\n",
    "\n",
    "        print(f'{self.model_names[model_index]} model is built')\n",
    "\n",
    "        print('Do you want to save the model? (y/n)')\n",
    "\n",
    "        model_save_flag = str(input().strip())\n",
    "\n",
    "        if model_save_flag.upper() == 'Y':\n",
    "            t_stamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "            model_file = f\"{t_stamp}.{self.model_names[model_index].replace(' ', '.')}.pickle\"\n",
    "            with open(model_file, 'wb') as model_file_ref:\n",
    "                pickle.dump(clf, model_file_ref)\n",
    "\n",
    "            print(f'The model is built and saved as {model_file}...')\n",
    "\n",
    "        self.selected_model = clf\n",
    "\n",
    "    def execute_model_prediction(self, x_validation, y_validation):\n",
    "        \"\"\"\n",
    "        This method will execute the model predictions and save the predictions\n",
    "        :param x_validation: X axis validation set\n",
    "        :param y_validation: Y axis validation set\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        accuracy = self.selected_model.score(x_validation, y_validation)\n",
    "\n",
    "        print(f'The accuracy of the model is {accuracy:.5f}')\n",
    "\n",
    "        #print(\"Do you want to see the confusion matrix? (y/n)\")\n",
    "\n",
    "        confuse_mtx_flag = 'Y' #str(input().strip())\n",
    "\n",
    "        y_pred = self.selected_model.predict(x_validation)\n",
    "\n",
    "        if confuse_mtx_flag.upper() == 'Y':\n",
    "            print(confusion_matrix(y_validation, y_pred))\n",
    "\n",
    "        #print(\"Do you want to save the outcome for the test data ? (y/n)\")\n",
    "\n",
    "        outcome_flag = 'Y' #str(input().strip())\n",
    "\n",
    "        if outcome_flag.upper() == 'Y':\n",
    "            y_pred = self.selected_model.predict(self.test_dataset[self.selected_features])\n",
    "            final_df = pd.DataFrame(y_pred,columns=[\"Illness\"])\n",
    "            final_result_df = self.test_dataset.append(final_df)\n",
    "            final_result_df.to_csv(self.test_data_output_csv)\n",
    "            input_df = pd.read_csv(self.test_data_output_csv)\n",
    "            pd.value_counts(input_df['Illness']).plot.barh()\n",
    "\n",
    "    def split_train_dataset(self):\n",
    "        \"\"\"\n",
    "        This method will split the input training data set and select the user features\n",
    "        :return: X axis training data set , Y axis training data set,\n",
    "         X axis validation data set  and Y axis validation data set\n",
    "        \"\"\"\n",
    "        feature_list = list(self.train_dataset.columns)\n",
    "\n",
    "        print('Select the features to consider (ex. 13 -> City, Age)')\n",
    "\n",
    "        for index in range(len(feature_list)-1):\n",
    "            print(f' {index+1}) { feature_list[index]}')\n",
    "\n",
    "        feature_index = int(input())\n",
    "\n",
    "        self.selected_features = [feature_list[int(feature_index)-1] for feature_index in str(feature_index)]\n",
    "\n",
    "        print(f'Features selected: {self.selected_features}')\n",
    "\n",
    "        print('Enter the train:validation split ratio (ex. 7:3)')\n",
    "        ratio_input = str(input().strip())\n",
    "        train_size = int(ratio_input[0]) * 0.01\n",
    "\n",
    "        x_train, x_validation, y_train, y_validation = \\\n",
    "            train_test_split(self.train_dataset[self.selected_features],\n",
    "                             self.train_dataset[self.prediction_column], train_size=train_size)\n",
    "\n",
    "        print(f'The train data is split into train and validation set with {ratio_input} ratio')\n",
    "\n",
    "        return x_train, x_validation, y_train, y_validation\n",
    "\n",
    "    def execute_workflow(self):\n",
    "        \"\"\"\n",
    "        This method will orchestrate the model execution flow\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x_train, x_validation, y_train, y_validation = None, None, None, None\n",
    "\n",
    "        while True:\n",
    "\n",
    "            try:\n",
    "                self.display_workflow_status()\n",
    "\n",
    "                flow_index = int(input().strip()) - 1\n",
    "\n",
    "                if flow_index > 0  and  \\\n",
    "                                self.workflow_dict[self.workflow_steps[flow_index - 1]] != \"COMPLETED\":\n",
    "                    print(f\"Incorrect value, please choose value less than {flow_index}, \"\n",
    "                          f\"Step {self.workflow_steps[flow_index - 1]} \"\n",
    "                          f\"has to complete to proceed further\")\n",
    "                    continue\n",
    "\n",
    "                if flow_index == 0:\n",
    "                    self.load_data()\n",
    "                elif flow_index == 1:\n",
    "                    self.train_dataset = self.preprocess_data(self.train_dataset)\n",
    "                    self.test_dataset = self.preprocess_data(self.test_dataset)\n",
    "                    x_train, x_validation, y_train, y_validation = self.split_train_dataset()\n",
    "\n",
    "                elif flow_index == 2:\n",
    "                    self.build_model(x_train_data=x_train, y_train_data=y_train)\n",
    "                    pass\n",
    "                elif flow_index == 3:\n",
    "                    self.execute_model_prediction(x_validation=x_validation, y_validation=y_validation)\n",
    "                else:\n",
    "                   return\n",
    "\n",
    "                self.workflow_dict[self.workflow_steps[flow_index]] = \"COMPLETED\"\n",
    "            except Exception as ex:\n",
    "                logging.error(ex)\n",
    "    def display_workflow_status(self):\n",
    "        \"\"\"\n",
    "        This method will display workflow steps\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "\n",
    "        for i, name in enumerate(self.workflow_dict):\n",
    "            print(f' {i+1}) {name} - { self.workflow_dict[name]}')\n",
    "\n",
    "        print('Please choose the workflow step: ')\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    This method will act as a trigger for the entire workflow\n",
    "    :return: None\n",
    "    To Update the train data and test data path\n",
    "    \"\"\"\n",
    "    train_data_path = './train_data.csv'\n",
    "    test_data_path = './test_data_X.csv'\n",
    "\n",
    "    illness_workflow = IllnessPredictionModelWorkflow(train_data_path=train_data_path,\n",
    "                                                      test_data_path=test_data_path)\n",
    "\n",
    "    print(\"Welcome! \")\n",
    "\n",
    "    illness_workflow.execute_workflow()\n",
    "\n",
    "    print('Closing Program. Goodbye.')\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./test_data_y_pred.csv\")\n",
    "\n",
    "pd.value_counts(df['Illness']).plot.barh(x='ABC', y='BVC')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
